{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import librairies ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport io\nimport cv2\nimport numpy as np\nfrom os import listdir\nfrom os.path import isfile, join\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications import ResNet50\n\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\nfrom skimage.feature import hog\nfrom skimage import data, exposure\n\nimport random\nimport os\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:24:45.206852Z","iopub.execute_input":"2022-08-15T19:24:45.207209Z","iopub.status.idle":"2022-08-15T19:24:52.540811Z","shell.execute_reply.started":"2022-08-15T19:24:45.207115Z","shell.execute_reply":"2022-08-15T19:24:52.539995Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing functions","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend as K\ndef preprocess_input(x, data_format=None, version=1):\n    \"\"\"\n    This function prepare the data for VGG Face based model.\n    It is necessary !!\n    :param x: The input images\n    :param data_format: The format of data: chennels at first or at last    \n    :param version: In which version we want our data to be in, two versions with different values to substract\n    :return: pre-processed images in an array format\n    \"\"\"\n    \n    x_temp = np.copy(x)\n    if data_format is None:\n        data_format = K.image_data_format()\n    assert data_format in {'channels_last', 'channels_first'}\n\n    if version == 1:\n        if data_format == 'channels_first':\n            x_temp = x_temp[:, ::-1, ...]\n            x_temp[:, 0, :, :] -= 93.5940\n            x_temp[:, 1, :, :] -= 104.7624\n            x_temp[:, 2, :, :] -= 129.1863\n        else:\n            x_temp = x_temp[..., ::-1]\n            x_temp[..., 0] -= 93.5940\n            x_temp[..., 1] -= 104.7624\n            x_temp[..., 2] -= 129.1863\n\n    elif version == 2:\n        if data_format == 'channels_first':\n            x_temp = x_temp[:, ::-1, ...]\n            x_temp[:, 0, :, :] -= 91.4953\n            x_temp[:, 1, :, :] -= 103.8827\n            x_temp[:, 2, :, :] -= 131.0912\n        else:\n            x_temp = x_temp[..., ::-1]\n            x_temp[..., 0] -= 91.4953\n            x_temp[..., 1] -= 103.8827\n            x_temp[..., 2] -= 131.0912\n    else:\n        raise NotImplementedError\n\n    return x_temp","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:24:58.544796Z","iopub.execute_input":"2022-08-15T19:24:58.545340Z","iopub.status.idle":"2022-08-15T19:24:58.555911Z","shell.execute_reply.started":"2022-08-15T19:24:58.545304Z","shell.execute_reply":"2022-08-15T19:24:58.555045Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from numpy.linalg import norm\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.linear_model import SGDOneClassSVM\nfrom sklearn.covariance import EllipticEnvelope\ndef get_clean_data(labels, embeds, names, threshold=9, method='distance'):\n    \"\"\"\n    This function clean the data-set\n    :param labels: the images labels\n    :param embeds: the images embeddings\n    :param names: the file names of the images\n    :param threshold: according to this threshold we classify each image\n    :param method: the method used to clean the data\n    :return: a tuple of the outliers, cleaned embedding and labels, each one in an array format\n    \"\"\"\n    outliers =  {}\n    clean_embed = []\n    clean_labels = []\n    for k in set(labels):\n        \n        if method == 'distance':\n            filter_ = []\n            center = sum(embeds[k])/len(embeds[k])\n            for e in embeds[k]:\n                filter_.append(norm(e - center))\n            filter_ = np.array(filter_)\n            outliers[k] = np.array(names[k])[np.where(filter_ >= threshold)]\n            clean_embed.extend(np.array(embeds[k])[np.where(filter_ < threshold)])\n            n = len(np.array(embeds[k])[np.where(filter_ < threshold)])\n            \n        elif method == 'Gauss':\n            m = np.mean(embeds[k], axis=0)\n            v = np.var(embeds[k], axis=0)\n            filter_ = multivariateGaussian(embeds[k], m, v)\n            outliers[k] = np.array(names[k])[np.where(filter_ <= threshold)]\n            clean_embed.extend(np.array(embeds[k])[np.where(filter_ > threshold)])\n            n = len(np.array(embeds[k])[np.where(filter_ > threshold)])\n        \n        elif method == 'one_class_svm':\n            filter_ = SGDOneClassSVM(random_state=0).fit_predict(embeds[k])\n            outliers[k] = np.array(names[k])[np.where(filter_ == -1)]\n            clean_embed.extend(np.array(embeds[k])[np.where(filter_ == 1)])\n            n = len(np.array(embeds[k])[np.where(filter_ == 1)])\n        clean_labels.extend([k]*n)\n        #print(filter_, np.array(names[k]))\n\n    return outliers, np.array(clean_embed), np.array(clean_labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:01.755395Z","iopub.execute_input":"2022-08-15T19:25:01.755656Z","iopub.status.idle":"2022-08-15T19:25:01.901897Z","shell.execute_reply.started":"2022-08-15T19:25:01.755628Z","shell.execute_reply":"2022-08-15T19:25:01.901129Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    \"\"\"\n    A class that generate data batches using their paths.\n    It is used when you have a big data-set that does not fit the memory\n    ...\n    \n    Attributes\n    ----------\n    dataset: dictionary\n        Its keys are the labels and its values are the paths of the images \n        of each label.\n    dataset_path: str\n        The path of the data-set\n    shuffle: bool\n        True if we want to shuffle the data and vice-versa\n    batch_size: int\n        The size of the batch\n    no_of_people: int\n        The number of labels (in our case people are the labels)\n        \n    Methods\n    -------\n    curate_dataset(dataset_path)\n        Create the data-set dictionary\n    on_epoch_end()\n        Shuffle the labels if shuffle=True\n    get_image(person, index)\n        Read, resize and pre-process the image (given at 'index' in the label 'person')\n    \"\"\"\n    \n    \n    def __init__(self, dataset_path, batch_size=20, shuffle=True):\n        \"\"\"\n        class initialization\n      \n        param: dataset_path: The path of the data-set\n        parma: shuffle: True if we want to shuffle the data and vice-versa \n        param: batch_size: The size of the batch\n        \"\"\"\n        \n        self.dataset = self.curate_dataset(dataset_path)\n        self.dataset_path = dataset_path\n        self.shuffle = shuffle\n        self.batch_size =batch_size\n        self.no_of_people = len(list(self.dataset.keys()))\n        self.on_epoch_end()\n        #print(self.dataset.keys())\n        \n    def __getitem__(self, index):\n        \"\"\"\n        Generate the batch\n        \n        param: index: the index of the batch\n        \"\"\"\n        \n        people = list(self.dataset.keys())[index * self.batch_size: (index + 1) * self.batch_size]\n        P = []\n        A = []\n        N = []\n        \n        for person in people:\n            anchor_index = random.randint(0, len(self.dataset[person])-1)\n            a = self.get_image(person, anchor_index)\n            \n            positive_index = random.randint(0, len(self.dataset[person])-1)\n            while positive_index == anchor_index and len(self.dataset[person]) != 1:\n                positive_index = random.randint(0, len(self.dataset[person])-1)\n                \n            p = self.get_image(person, positive_index)\n            \n            negative_person_index = random.randint(0, self.no_of_people - 1)\n            negative_person = list(self.dataset.keys())[negative_person_index]\n            while negative_person == person:\n                negative_person_index = random.randint(0, self.no_of_people - 1)\n                negative_person = list(self.dataset.keys())[negative_person_index]\n            \n            negative_index = random.randint(0, len(self.dataset[negative_person])-1)\n            n = self.get_image(negative_person, negative_index)\n            P.append(p)\n            A.append(a)\n            N.append(n)\n        A = np.asarray(A)\n        N = np.asarray(N)\n        P = np.asarray(P)\n        return [A, P, N]\n        \n    def __len__(self):\n        return self.no_of_people // self.batch_size\n        \n    def curate_dataset(self, dataset_path):\n        \"\"\"\n        create the data-set dictionary. Its keys are the labels and its values \n        are the paths of the images of each label.\n        \n        param: dataset_path: the path of the data-set\n        \"\"\"\n        \n        dataset = {}\n        dirs = [dir for dir in listdir(dataset_path)]\n        for dir in dirs: \n            fichiers = [f for f in listdir(dataset_path+dir) if \"jpeg\" in f or \"png\" in f]\n            for f in fichiers:\n                if dir in dataset.keys():\n                    dataset[dir].append(f)\n                else:\n                    dataset[dir] = [f]\n        return dataset\n    \n    def on_epoch_end(self):\n        \"\"\"\n        shuffle the labels if shuffle=True \n        \"\"\"\n        if self.shuffle:\n            keys = list(self.dataset.keys())\n            random.shuffle(keys)\n            dataset_ =  {}\n            for key in keys:\n                dataset_[key] = self.dataset[key]\n            self.dataset = dataset_\n            \n    def get_image(self, person, index): \n        \"\"\"\n        read, resize and pre-process the image\n        \n        param: person: the label (celebrity name)\n        param: index: the image of index \"index\" in the list dataset[person]\n        :return: pre-processed image\n        \"\"\"\n        img = cv2.imread(os.path.join(self.dataset_path, os.path.join(person, self.dataset[person][index])))\n        img = cv2.resize(img, (224, 224))\n        img = np.asarray(img, dtype=np.float64)\n        img = preprocess_input(img)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:03.245027Z","iopub.execute_input":"2022-08-15T19:25:03.245291Z","iopub.status.idle":"2022-08-15T19:25:03.262273Z","shell.execute_reply.started":"2022-08-15T19:25:03.245259Z","shell.execute_reply":"2022-08-15T19:25:03.261485Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# VGG Face model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n\ndef vgg_face():\t\n    \"\"\"\n    The VGG Face architecture\n    :return: the vgg face architecture\n    \"\"\"\n    \n    model = Sequential()\n    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n    model.add(Convolution2D(64, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(128, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Convolution2D(2622, (1, 1)))\n    model.add(Flatten())\n    model.add(Activation('softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:04.247299Z","iopub.execute_input":"2022-08-15T19:25:04.247862Z","iopub.status.idle":"2022-08-15T19:25:04.265228Z","shell.execute_reply.started":"2022-08-15T19:25:04.247826Z","shell.execute_reply":"2022-08-15T19:25:04.264334Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Siamese Network","metadata":{}},{"cell_type":"code","source":"class SiameseNetwork(tf.keras.Model):\n    \"\"\"\n    A class that ceates the siamese network\n    ...\n    \n    Attributes\n    ----------\n    vgg_face: neural network architecture of VGG Face\n    \n    Methods\n    -------\n    call(inputs)\n        Return the VGG Face mappings of the anchor, the positive and the negative images\n    get_features(inputs)\n        Return the VGG Face mappings\n    \"\"\"\n    \n    def __init__(self, vgg_face):\n        \"\"\"\n        Class initialization\n        \n        param: vgg_face:  the model used for Siamese network\n        \"\"\"\n        \n        super(SiameseNetwork, self).__init__()\n        self.vgg_face = vgg_face\n        \n    @tf.function\n    def call(self, inputs):\n        \"\"\"\n        This function gives the VGG Face mappings of the anchor, the positive and the negative image\n    \n        param: inputs: list of the anchor, the positive and the negative images \n        :return: list of the embeddings of the anchor, the positive and the negative images\n        \"\"\"\n        \n        image_1, image_2, image_3 =  inputs\n        with tf.name_scope(\"Anchor\") as scope:\n            feature_1 = self.vgg_face(image_1)\n            feature_1 = tf.math.l2_normalize(feature_1, axis=-1)\n        with tf.name_scope(\"Positive\") as scope:\n            feature_2 = self.vgg_face(image_2)\n            feature_2 = tf.math.l2_normalize(feature_2, axis=-1)\n        with tf.name_scope(\"Negative\") as scope:\n            feature_3 = self.vgg_face(image_3)\n            feature_3 = tf.math.l2_normalize(feature_3, axis=-1)\n        return [feature_1, feature_2, feature_3]\n    \n    @tf.function\n    def get_features(self, inputs):\n        \"\"\"\n        VGG Face mappings \n\n        param: inputs: list of the anchor, the positive and the negative images\n        :return: list of l2 normalized embeddings of the anchor, the positive and the negative images\n        \"\"\"\n        return tf.math.l2_normalize(self.vgg_face(inputs, training=False), axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:05.299973Z","iopub.execute_input":"2022-08-15T19:25:05.300682Z","iopub.status.idle":"2022-08-15T19:25:05.309279Z","shell.execute_reply.started":"2022-08-15T19:25:05.300647Z","shell.execute_reply":"2022-08-15T19:25:05.308401Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def loss_function(x, alpha = 0.2):\n    \"\"\"\n    Compute the loss function \n    \n    param: x: list of VGG Face embeddings of the anchor, the positive and the negative images\n    param: alpha: the fixed margin loss\n    :return: the value of the loss function\n    \"\"\"\n    \n    K = tf.keras.backend\n    # Triplet Loss function.\n    anchor,positive,negative = x\n    # distance between the anchor and the positive\n    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n    # distance between the anchor and the negative\n    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n    # compute loss\n    basic_loss = pos_dist-neg_dist+alpha\n    loss = K.mean(K.maximum(basic_loss,0.0))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:07.459246Z","iopub.execute_input":"2022-08-15T19:25:07.460086Z","iopub.status.idle":"2022-08-15T19:25:07.466356Z","shell.execute_reply.started":"2022-08-15T19:25:07.460033Z","shell.execute_reply":"2022-08-15T19:25:07.465568Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train(X):\n    \"\"\"\n    Compute the loss after applying \"Adam\" optimizer\n    \n    param: X: list of the anchor, the positive and the negative images\n    :return: the value of the loss function\n    \"\"\"\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00006)\n    with tf.GradientTape() as tape:\n        y_pred = model(X)\n        loss = loss_function(y_pred)\n    grad = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:08.497897Z","iopub.execute_input":"2022-08-15T19:25:08.498868Z","iopub.status.idle":"2022-08-15T19:25:08.504472Z","shell.execute_reply.started":"2022-08-15T19:25:08.498813Z","shell.execute_reply":"2022-08-15T19:25:08.503246Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Create the model","metadata":{}},{"cell_type":"code","source":"#Create VGG Face model\nmodel = vgg_face()\nmodel.load_weights('../input/weights/vgg_face_weights.h5')\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:32.155568Z","iopub.execute_input":"2022-08-15T19:25:32.155855Z","iopub.status.idle":"2022-08-15T19:25:40.497666Z","shell.execute_reply.started":"2022-08-15T19:25:32.155821Z","shell.execute_reply":"2022-08-15T19:25:40.496933Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Add extra-layers to train the model on our images (Transfer Learning)\nmodel.pop()\nmodel.add(tf.keras.layers.Dense(2*512))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(128, use_bias=False, name='output'))\n\n# Freeze all the layers except the added ones\nfor layer in model.layers[:-3]:\n    layer.trainable = False\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:25:43.123968Z","iopub.execute_input":"2022-08-15T19:25:43.124282Z","iopub.status.idle":"2022-08-15T19:25:43.468817Z","shell.execute_reply.started":"2022-08-15T19:25:43.124246Z","shell.execute_reply":"2022-08-15T19:25:43.467139Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Create the siamese model based on VGG Face\nmodel = SiameseNetwork(model)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T15:26:23.761030Z","iopub.execute_input":"2022-08-15T15:26:23.761719Z","iopub.status.idle":"2022-08-15T15:26:23.768302Z","shell.execute_reply.started":"2022-08-15T15:26:23.761683Z","shell.execute_reply":"2022-08-15T15:26:23.767541Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"# load our data in an online manner\ndata_generator = DataGenerator(dataset_path='../input/big-dataset/big_dataset/Train/', batch_size=20)\n\n# Train the model\nlosses = []\naccuracy = []\nepochs = 30\nno_of_batches = len(data_generator)\nfor i in range(1, epochs+1, 1):\n    loss = 0\n    with tqdm(total=no_of_batches) as pbar:\n        \n        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n        pbar.set_description_str(description)\n        \n        for j in range(no_of_batches):\n            data = data_generator[j]\n            temp = train(data)\n            loss += temp\n            \n            pbar.update()\n            print_statement = \"Loss :\" + str(temp.numpy())\n            pbar.set_postfix_str(print_statement)\n        \n        loss /= no_of_batches\n        \n        losses.append(loss.numpy())\n        print_statement = \"Loss :\" + str(loss.numpy())\n        pbar.set_postfix_str(print_statement)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T15:26:24.981635Z","iopub.execute_input":"2022-08-15T15:26:24.981898Z","iopub.status.idle":"2022-08-15T15:55:15.396869Z","shell.execute_reply.started":"2022-08-15T15:26:24.981868Z","shell.execute_reply":"2022-08-15T15:55:15.396140Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"markdown","source":"## Distance computing classifier","metadata":{}},{"cell_type":"code","source":"# Create the training embeddings and labels \ndata_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/train/')\ntrain_dict = data_generator.curate_dataset('../input/dataset6/dataset4/train/')\nlabels = []\nfeatures = []\n\n# compute the embeddings of the images\ni = 0\nfor k, v in train_dict.items():\n    images = []\n    for e in v:\n        image_path = '../input/dataset6/dataset4/train/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        images.append(image)\n\n    images = np.asarray(images)\n    images = preprocess_input(images)\n    images = tf.convert_to_tensor(images)\n    feature = model.get_features(images)\n    feature = tf.reduce_mean(feature, axis=0)\n    features.append(feature.numpy())\n    labels.append(k)\n    \nfeatures = np.asarray(features)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T16:04:45.665955Z","iopub.execute_input":"2022-08-15T16:04:45.666728Z","iopub.status.idle":"2022-08-15T16:04:55.946397Z","shell.execute_reply.started":"2022-08-15T16:04:45.666692Z","shell.execute_reply":"2022-08-15T16:04:55.944521Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Create the training images and labels \ndata_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/test/')\ntest_dict = data_generator.curate_dataset('../input/dataset6/dataset4/test/')\n\n# prepare testing data\nlabels_test = []\nimages_test = []\ni = 0\nfor k, v in test_dict.items():\n    for e in v:\n        image_path = '../input/dataset6/dataset4/test/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        images_test.append(image)\n        labels_test.append(k)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:33:59.543679Z","iopub.execute_input":"2022-03-17T15:33:59.543935Z","iopub.status.idle":"2022-03-17T15:34:01.05118Z","shell.execute_reply.started":"2022-03-17T15:33:59.543901Z","shell.execute_reply":"2022-03-17T15:34:01.050396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\n# shuffle the data\nfeatures, labels = shuffle(features, labels)\nimages_test, labels_test = shuffle(images_test, labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:01.053333Z","iopub.execute_input":"2022-03-17T15:34:01.053595Z","iopub.status.idle":"2022-03-17T15:34:01.058815Z","shell.execute_reply.started":"2022-03-17T15:34:01.053561Z","shell.execute_reply":"2022-03-17T15:34:01.058157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(images):\n    \"\"\"\n    This function compute the predictions.\n    \n    param: images: array of images that we want to predict their labels.\n    :return: list of predictions.\n    \"\"\"\n    preds = []\n    for image in images:\n        image = preprocess_input(image)\n        img_features = model.get_features(np.expand_dims(image, axis=0))\n        dist = tf.norm(img_features - features, axis=1)\n        preds.append(labels[tf.argmin(dist)])\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:01.059847Z","iopub.execute_input":"2022-03-17T15:34:01.060436Z","iopub.status.idle":"2022-03-17T15:34:01.069788Z","shell.execute_reply.started":"2022-03-17T15:34:01.060399Z","shell.execute_reply":"2022-03-17T15:34:01.06895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nfrom sklearn.metrics import accuracy_score\npreds = predict(images_test)\naccuracy_score(preds, labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:01.073024Z","iopub.execute_input":"2022-03-17T15:34:01.07327Z","iopub.status.idle":"2022-03-17T15:34:20.625511Z","shell.execute_reply.started":"2022-03-17T15:34:01.073228Z","shell.execute_reply":"2022-03-17T15:34:20.624874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of predicting an image\nimport matplotlib.image as mpimg\nimage_path = '../input/dataset5/dataset3/test/Adílio/Adílio17.jpeg'\nplt.imshow(mpimg.imread(image_path))\nimage = cv2.imread(image_path)\nimage = np.asarray(image, dtype=np.float64)\npredict([image])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T09:38:40.835664Z","iopub.execute_input":"2022-03-15T09:38:40.835969Z","iopub.status.idle":"2022-03-15T09:38:41.112947Z","shell.execute_reply.started":"2022-03-15T09:38:40.835926Z","shell.execute_reply":"2022-03-15T09:38:41.112244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM classifier","metadata":{}},{"cell_type":"code","source":"# Create labels and embedding for training\ntrain_dict = data_generator.curate_dataset('../input/big-dataset/big_dataset/Train/')\nlabels_train = []\nfeatures_train = []\nnames_train = []\n\n# compute the embeddings \nfor k, v in train_dict.items():\n    images = []\n    for e in v:\n        image_path = '../input/big-dataset/big_dataset/Train/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        image = cv2.resize(image, (224, 224))\n        image = preprocess_input(image)\n        img_features = model.get_features(np.expand_dims(image, axis=0))\n        features_train.append(img_features[0].numpy())\n        labels_train.append(k)\n        names_train.append(e)\n\nnames_train = np.asarray(names_train)\nlabels_train = np.asarray(labels_train)\nfeatures_train = np.asarray(features_train)\n\n# save names, labels and embeddings in a .npy format\nnp.save('names_train', names_train)\nnp.save('labels_train', labels_train)\nnp.save('features_train', features_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T16:05:01.534591Z","iopub.execute_input":"2022-08-15T16:05:01.535065Z","iopub.status.idle":"2022-08-15T16:14:05.191185Z","shell.execute_reply.started":"2022-08-15T16:05:01.535028Z","shell.execute_reply":"2022-08-15T16:14:05.190253Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Create labels and embeddings for testing\ntest_dict = data_generator.curate_dataset('../input/big-dataset/big_dataset/Test/')\nlabels_test = []\nfeatures_test = []\nnames_test = []\n\n# compute embeddings\nfor k, v in test_dict.items():\n    images = []\n    for e in v:\n        image_path = '../input/big-dataset/big_dataset/Test/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        image = cv2.resize(image, (224, 224))\n        image = preprocess_input(image)\n        img_features = model.get_features(np.expand_dims(image, axis=0))\n        features_test.append(img_features[0].numpy())\n        labels_test.append(k)\n        names_test.append(e)\n\nnames_test = np.asarray(names_test)\nlabels_test = np.asarray(labels_test)\nfeatures_test = np.asarray(features_test)\n\n# save names, labels and embeddings in a .npy format\nnp.save('names_test', names_test)\nnp.save('labels_test', labels_test)\nnp.save('features_test', features_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T16:14:05.193519Z","iopub.execute_input":"2022-08-15T16:14:05.193932Z","iopub.status.idle":"2022-08-15T16:17:51.006976Z","shell.execute_reply.started":"2022-08-15T16:14:05.193897Z","shell.execute_reply":"2022-08-15T16:17:51.005991Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# load the npy files\nnames_train = np.load('../input/embed-labels-names/names_train.npy')\nlabels_train = np.load('../input/embed-labels-names/labels_train.npy')\nfeatures_train = np.load('../input/embed-labels-names/features_train.npy')\n\nnames_test = np.load('../input/embed-labels-names/names_test.npy')\nlabels_test = np.load('../input/embed-labels-names/labels_test.npy')\nfeatures_test = np.load('../input/embed-labels-names/features_test.npy')","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:26:10.462830Z","iopub.execute_input":"2022-08-15T19:26:10.463404Z","iopub.status.idle":"2022-08-15T19:26:10.774393Z","shell.execute_reply.started":"2022-08-15T19:26:10.463365Z","shell.execute_reply":"2022-08-15T19:26:10.773392Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\n# create dictionaries for embedding and names in order to pass them as argument to the cleaning function (get_clean_data)\nembeds_train_dict = defaultdict(list)\nnames_train_dict = defaultdict(list)\nfor i, k in enumerate(labels_train):\n    embeds_train_dict[k].append(features_train[i])\n    names_train_dict[k].append(names_train[i])\n\nnames_test_dict = defaultdict(list)\nembeds_test_dict = defaultdict(list)\nfor i, k in enumerate(labels_test):\n    embeds_test_dict[k].append(features_test[i])\n    names_test_dict[k].append(names_test[i])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:26:11.813256Z","iopub.execute_input":"2022-08-15T19:26:11.813528Z","iopub.status.idle":"2022-08-15T19:26:11.876842Z","shell.execute_reply.started":"2022-08-15T19:26:11.813497Z","shell.execute_reply":"2022-08-15T19:26:11.876122Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# clean the data\noutliers_train, clean_embed_train, clean_labels_train = get_clean_data(labels_train, embeds_train_dict, names_train_dict)\noutliers_test, clean_embed_test, clean_labels_test = get_clean_data(labels_test, embeds_test_dict, names_test_dict)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:26:13.616948Z","iopub.execute_input":"2022-08-15T19:26:13.617430Z","iopub.status.idle":"2022-08-15T19:26:14.189621Z","shell.execute_reply.started":"2022-08-15T19:26:13.617393Z","shell.execute_reply":"2022-08-15T19:26:14.188795Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\n# shuffle the data\nclean_embed_train, clean_labels_train = shuffle(clean_embed_train, clean_labels_train)\nclean_embed_test, clean_labels_test = shuffle(clean_embed_test, clean_labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:26:15.034552Z","iopub.execute_input":"2022-08-15T19:26:15.035099Z","iopub.status.idle":"2022-08-15T19:26:15.055927Z","shell.execute_reply.started":"2022-08-15T19:26:15.035055Z","shell.execute_reply":"2022-08-15T19:26:15.054984Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Use SVM classifier with GridSearchCV to classfy these embedding\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\ntuned_parameters = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\nclf = GridSearchCV(SVC(), tuned_parameters)\nclf.fit(clean_embed_train, clean_labels_train)\nprint(\"Best parameters set found on development set:\")\nprint()\nprint(clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T16:45:53.940124Z","iopub.execute_input":"2022-08-15T16:45:53.940901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n# Accuracy\npreds = clf.predict(clean_embed_test)\nprint(\"Accuracy :  \", accuracy_score(clean_labels_test, preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random forest classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:29:05.686744Z","iopub.execute_input":"2022-08-15T19:29:05.687597Z","iopub.status.idle":"2022-08-15T19:29:05.695991Z","shell.execute_reply.started":"2022-08-15T19:29:05.687554Z","shell.execute_reply":"2022-08-15T19:29:05.695258Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(type(list(clean_labels_test)))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:31:09.333470Z","iopub.execute_input":"2022-08-15T19:31:09.333795Z","iopub.status.idle":"2022-08-15T19:31:09.343897Z","shell.execute_reply.started":"2022-08-15T19:31:09.333743Z","shell.execute_reply":"2022-08-15T19:31:09.342987Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Transfort the labels to integers\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(list(clean_labels_test) + list(clean_labels_train))\nencoded_labels_train = le.transform(clean_labels_train)\nencoded_labels_test = le.transform(clean_labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:31:37.214329Z","iopub.execute_input":"2022-08-15T19:31:37.215002Z","iopub.status.idle":"2022-08-15T19:31:37.275454Z","shell.execute_reply.started":"2022-08-15T19:31:37.214963Z","shell.execute_reply":"2022-08-15T19:31:37.274611Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Train Random Forest Classifier and find the best parameters using Random Search Cross Validation\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nclf_random.fit(clean_embed_train, encoded_labels_train)\nprint(clf_random.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:31:42.103943Z","iopub.execute_input":"2022-08-15T19:31:42.104499Z","iopub.status.idle":"2022-08-15T20:01:30.298808Z","shell.execute_reply.started":"2022-08-15T19:31:42.104458Z","shell.execute_reply":"2022-08-15T20:01:30.295187Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nfrom sklearn.metrics import accuracy_score\npreds = clf_random.predict(clean_embed_test)\nprint(\"Accuracy :  \", accuracy_score(encoded_labels_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T20:01:30.300364Z","iopub.status.idle":"2022-08-15T20:01:30.300923Z","shell.execute_reply.started":"2022-08-15T20:01:30.300675Z","shell.execute_reply":"2022-08-15T20:01:30.300702Z"},"trusted":true},"execution_count":null,"outputs":[]}]}