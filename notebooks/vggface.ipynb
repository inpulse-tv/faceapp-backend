{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:24:45.207209Z",
     "iopub.status.busy": "2022-08-15T19:24:45.206852Z",
     "iopub.status.idle": "2022-08-15T19:24:52.540811Z",
     "shell.execute_reply": "2022-08-15T19:24:52.539995Z",
     "shell.execute_reply.started": "2022-08-15T19:24:45.207115Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:24:58.545340Z",
     "iopub.status.busy": "2022-08-15T19:24:58.544796Z",
     "iopub.status.idle": "2022-08-15T19:24:58.555911Z",
     "shell.execute_reply": "2022-08-15T19:24:58.555045Z",
     "shell.execute_reply.started": "2022-08-15T19:24:58.545304Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def preprocess_input(x, data_format=None, version=1):\n",
    "    \"\"\"\n",
    "    This function prepare the data for VGG Face based model.\n",
    "    It is necessary !!\n",
    "    :param x: The input images\n",
    "    :param data_format: The format of data: chennels at first or at last    \n",
    "    :param version: In which version we want our data to be in, two versions with different values to substract\n",
    "    :return: pre-processed images in an array format\n",
    "    \"\"\"\n",
    "    \n",
    "    x_temp = np.copy(x)\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "    if version == 1:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 93.5940\n",
    "            x_temp[:, 1, :, :] -= 104.7624\n",
    "            x_temp[:, 2, :, :] -= 129.1863\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 93.5940\n",
    "            x_temp[..., 1] -= 104.7624\n",
    "            x_temp[..., 2] -= 129.1863\n",
    "\n",
    "    elif version == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 91.4953\n",
    "            x_temp[:, 1, :, :] -= 103.8827\n",
    "            x_temp[:, 2, :, :] -= 131.0912\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 91.4953\n",
    "            x_temp[..., 1] -= 103.8827\n",
    "            x_temp[..., 2] -= 131.0912\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return x_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:01.755656Z",
     "iopub.status.busy": "2022-08-15T19:25:01.755395Z",
     "iopub.status.idle": "2022-08-15T19:25:01.901897Z",
     "shell.execute_reply": "2022-08-15T19:25:01.901129Z",
     "shell.execute_reply.started": "2022-08-15T19:25:01.755628Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "def get_clean_data(labels, embeds, names, threshold=9, method='distance'):\n",
    "    \"\"\"\n",
    "    This function clean the data-set\n",
    "    :param labels: the images labels\n",
    "    :param embeds: the images embeddings\n",
    "    :param names: the file names of the images\n",
    "    :param threshold: according to this threshold we classify each image\n",
    "    :param method: the method used to clean the data\n",
    "    :return: a tuple of the outliers, cleaned embedding and labels, each one in an array format\n",
    "    \"\"\"\n",
    "    outliers =  {}\n",
    "    clean_embed = []\n",
    "    clean_labels = []\n",
    "    for k in set(labels):\n",
    "        \n",
    "        if method == 'distance':\n",
    "            filter_ = []\n",
    "            center = sum(embeds[k])/len(embeds[k])\n",
    "            for e in embeds[k]:\n",
    "                filter_.append(norm(e - center))\n",
    "            filter_ = np.array(filter_)\n",
    "            outliers[k] = np.array(names[k])[np.where(filter_ >= threshold)]\n",
    "            clean_embed.extend(np.array(embeds[k])[np.where(filter_ < threshold)])\n",
    "            n = len(np.array(embeds[k])[np.where(filter_ < threshold)])\n",
    "            \n",
    "        elif method == 'Gauss':\n",
    "            m = np.mean(embeds[k], axis=0)\n",
    "            v = np.var(embeds[k], axis=0)\n",
    "            filter_ = multivariateGaussian(embeds[k], m, v)\n",
    "            outliers[k] = np.array(names[k])[np.where(filter_ <= threshold)]\n",
    "            clean_embed.extend(np.array(embeds[k])[np.where(filter_ > threshold)])\n",
    "            n = len(np.array(embeds[k])[np.where(filter_ > threshold)])\n",
    "        \n",
    "        elif method == 'one_class_svm':\n",
    "            filter_ = SGDOneClassSVM(random_state=0).fit_predict(embeds[k])\n",
    "            outliers[k] = np.array(names[k])[np.where(filter_ == -1)]\n",
    "            clean_embed.extend(np.array(embeds[k])[np.where(filter_ == 1)])\n",
    "            n = len(np.array(embeds[k])[np.where(filter_ == 1)])\n",
    "        clean_labels.extend([k]*n)\n",
    "        #print(filter_, np.array(names[k]))\n",
    "\n",
    "    return outliers, np.array(clean_embed), np.array(clean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:03.245291Z",
     "iopub.status.busy": "2022-08-15T19:25:03.245027Z",
     "iopub.status.idle": "2022-08-15T19:25:03.262273Z",
     "shell.execute_reply": "2022-08-15T19:25:03.261485Z",
     "shell.execute_reply.started": "2022-08-15T19:25:03.245259Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    A class that generate data batches using their paths.\n",
    "    It is used when you have a big data-set that does not fit the memory\n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    dataset: dictionary\n",
    "        Its keys are the labels and its values are the paths of the images \n",
    "        of each label.\n",
    "    dataset_path: str\n",
    "        The path of the data-set\n",
    "    shuffle: bool\n",
    "        True if we want to shuffle the data and vice-versa\n",
    "    batch_size: int\n",
    "        The size of the batch\n",
    "    no_of_people: int\n",
    "        The number of labels (in our case people are the labels)\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    curate_dataset(dataset_path)\n",
    "        Create the data-set dictionary\n",
    "    on_epoch_end()\n",
    "        Shuffle the labels if shuffle=True\n",
    "    get_image(person, index)\n",
    "        Read, resize and pre-process the image (given at 'index' in the label 'person')\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, dataset_path, batch_size=20, shuffle=True):\n",
    "        \"\"\"\n",
    "        class initialization\n",
    "      \n",
    "        param: dataset_path: The path of the data-set\n",
    "        parma: shuffle: True if we want to shuffle the data and vice-versa \n",
    "        param: batch_size: The size of the batch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset = self.curate_dataset(dataset_path)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size =batch_size\n",
    "        self.no_of_people = len(list(self.dataset.keys()))\n",
    "        self.on_epoch_end()\n",
    "        #print(self.dataset.keys())\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate the batch\n",
    "        \n",
    "        param: index: the index of the batch\n",
    "        \"\"\"\n",
    "        \n",
    "        people = list(self.dataset.keys())[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        P = []\n",
    "        A = []\n",
    "        N = []\n",
    "        \n",
    "        for person in people:\n",
    "            anchor_index = random.randint(0, len(self.dataset[person])-1)\n",
    "            a = self.get_image(person, anchor_index)\n",
    "            \n",
    "            positive_index = random.randint(0, len(self.dataset[person])-1)\n",
    "            while positive_index == anchor_index and len(self.dataset[person]) != 1:\n",
    "                positive_index = random.randint(0, len(self.dataset[person])-1)\n",
    "                \n",
    "            p = self.get_image(person, positive_index)\n",
    "            \n",
    "            negative_person_index = random.randint(0, self.no_of_people - 1)\n",
    "            negative_person = list(self.dataset.keys())[negative_person_index]\n",
    "            while negative_person == person:\n",
    "                negative_person_index = random.randint(0, self.no_of_people - 1)\n",
    "                negative_person = list(self.dataset.keys())[negative_person_index]\n",
    "            \n",
    "            negative_index = random.randint(0, len(self.dataset[negative_person])-1)\n",
    "            n = self.get_image(negative_person, negative_index)\n",
    "            P.append(p)\n",
    "            A.append(a)\n",
    "            N.append(n)\n",
    "        A = np.asarray(A)\n",
    "        N = np.asarray(N)\n",
    "        P = np.asarray(P)\n",
    "        return [A, P, N]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.no_of_people // self.batch_size\n",
    "        \n",
    "    def curate_dataset(self, dataset_path):\n",
    "        \"\"\"\n",
    "        create the data-set dictionary. Its keys are the labels and its values \n",
    "        are the paths of the images of each label.\n",
    "        \n",
    "        param: dataset_path: the path of the data-set\n",
    "        \"\"\"\n",
    "        \n",
    "        dataset = {}\n",
    "        dirs = [dir for dir in listdir(dataset_path)]\n",
    "        for dir in dirs: \n",
    "            fichiers = [f for f in listdir(dataset_path+dir) if \"jpeg\" in f or \"png\" in f]\n",
    "            for f in fichiers:\n",
    "                if dir in dataset.keys():\n",
    "                    dataset[dir].append(f)\n",
    "                else:\n",
    "                    dataset[dir] = [f]\n",
    "        return dataset\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        shuffle the labels if shuffle=True \n",
    "        \"\"\"\n",
    "        if self.shuffle:\n",
    "            keys = list(self.dataset.keys())\n",
    "            random.shuffle(keys)\n",
    "            dataset_ =  {}\n",
    "            for key in keys:\n",
    "                dataset_[key] = self.dataset[key]\n",
    "            self.dataset = dataset_\n",
    "            \n",
    "    def get_image(self, person, index): \n",
    "        \"\"\"\n",
    "        read, resize and pre-process the image\n",
    "        \n",
    "        param: person: the label (celebrity name)\n",
    "        param: index: the image of index \"index\" in the list dataset[person]\n",
    "        :return: pre-processed image\n",
    "        \"\"\"\n",
    "        img = cv2.imread(os.path.join(self.dataset_path, os.path.join(person, self.dataset[person][index])))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.asarray(img, dtype=np.float64)\n",
    "        img = preprocess_input(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:04.247862Z",
     "iopub.status.busy": "2022-08-15T19:25:04.247299Z",
     "iopub.status.idle": "2022-08-15T19:25:04.265228Z",
     "shell.execute_reply": "2022-08-15T19:25:04.264334Z",
     "shell.execute_reply.started": "2022-08-15T19:25:04.247826Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "\n",
    "def vgg_face():\t\n",
    "    \"\"\"\n",
    "    The VGG Face architecture\n",
    "    :return: the vgg face architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:05.300682Z",
     "iopub.status.busy": "2022-08-15T19:25:05.299973Z",
     "iopub.status.idle": "2022-08-15T19:25:05.309279Z",
     "shell.execute_reply": "2022-08-15T19:25:05.308401Z",
     "shell.execute_reply.started": "2022-08-15T19:25:05.300647Z"
    }
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A class that ceates the siamese network\n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    vgg_face: neural network architecture of VGG Face\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    call(inputs)\n",
    "        Return the VGG Face mappings of the anchor, the positive and the negative images\n",
    "    get_features(inputs)\n",
    "        Return the VGG Face mappings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vgg_face):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        \n",
    "        param: vgg_face:  the model used for Siamese network\n",
    "        \"\"\"\n",
    "        \n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.vgg_face = vgg_face\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        This function gives the VGG Face mappings of the anchor, the positive and the negative image\n",
    "    \n",
    "        param: inputs: list of the anchor, the positive and the negative images \n",
    "        :return: list of the embeddings of the anchor, the positive and the negative images\n",
    "        \"\"\"\n",
    "        \n",
    "        image_1, image_2, image_3 =  inputs\n",
    "        with tf.name_scope(\"Anchor\") as scope:\n",
    "            feature_1 = self.vgg_face(image_1)\n",
    "            feature_1 = tf.math.l2_normalize(feature_1, axis=-1)\n",
    "        with tf.name_scope(\"Positive\") as scope:\n",
    "            feature_2 = self.vgg_face(image_2)\n",
    "            feature_2 = tf.math.l2_normalize(feature_2, axis=-1)\n",
    "        with tf.name_scope(\"Negative\") as scope:\n",
    "            feature_3 = self.vgg_face(image_3)\n",
    "            feature_3 = tf.math.l2_normalize(feature_3, axis=-1)\n",
    "        return [feature_1, feature_2, feature_3]\n",
    "    \n",
    "    @tf.function\n",
    "    def get_features(self, inputs):\n",
    "        \"\"\"\n",
    "        VGG Face mappings \n",
    "\n",
    "        param: inputs: list of the anchor, the positive and the negative images\n",
    "        :return: list of l2 normalized embeddings of the anchor, the positive and the negative images\n",
    "        \"\"\"\n",
    "        return tf.math.l2_normalize(self.vgg_face(inputs, training=False), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:07.460086Z",
     "iopub.status.busy": "2022-08-15T19:25:07.459246Z",
     "iopub.status.idle": "2022-08-15T19:25:07.466356Z",
     "shell.execute_reply": "2022-08-15T19:25:07.465568Z",
     "shell.execute_reply.started": "2022-08-15T19:25:07.460033Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(x, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Compute the loss function \n",
    "    \n",
    "    param: x: list of VGG Face embeddings of the anchor, the positive and the negative images\n",
    "    param: alpha: the fixed margin loss\n",
    "    :return: the value of the loss function\n",
    "    \"\"\"\n",
    "    \n",
    "    K = tf.keras.backend\n",
    "    # Triplet Loss function.\n",
    "    anchor,positive,negative = x\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.mean(K.maximum(basic_loss,0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:08.498868Z",
     "iopub.status.busy": "2022-08-15T19:25:08.497897Z",
     "iopub.status.idle": "2022-08-15T19:25:08.504472Z",
     "shell.execute_reply": "2022-08-15T19:25:08.503246Z",
     "shell.execute_reply.started": "2022-08-15T19:25:08.498813Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X):\n",
    "    \"\"\"\n",
    "    Compute the loss after applying \"Adam\" optimizer\n",
    "    \n",
    "    param: X: list of the anchor, the positive and the negative images\n",
    "    :return: the value of the loss function\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00006)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = loss_function(y_pred)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:32.155855Z",
     "iopub.status.busy": "2022-08-15T19:25:32.155568Z",
     "iopub.status.idle": "2022-08-15T19:25:40.497666Z",
     "shell.execute_reply": "2022-08-15T19:25:40.496933Z",
     "shell.execute_reply.started": "2022-08-15T19:25:32.155821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create VGG Face model\n",
    "# You can download the weights from this link https://www.kaggle.com/datasets/acharyarupak391/vggfaceweights\n",
    "model = vgg_face()\n",
    "model.load_weights('../input/weights/vgg_face_weights.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-08-15T19:25:43.124282Z",
     "iopub.status.busy": "2022-08-15T19:25:43.123968Z",
     "iopub.status.idle": "2022-08-15T19:25:43.468817Z",
     "shell.execute_reply": "2022-08-15T19:25:43.467139Z",
     "shell.execute_reply.started": "2022-08-15T19:25:43.124246Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add extra-layers to train the model on our images (Transfer Learning)\n",
    "model.pop()\n",
    "model.add(tf.keras.layers.Dense(2*512))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(128, use_bias=False, name='output'))\n",
    "\n",
    "# Freeze all the layers except the added ones\n",
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T15:26:23.761719Z",
     "iopub.status.busy": "2022-08-15T15:26:23.761030Z",
     "iopub.status.idle": "2022-08-15T15:26:23.768302Z",
     "shell.execute_reply": "2022-08-15T15:26:23.767541Z",
     "shell.execute_reply.started": "2022-08-15T15:26:23.761683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the siamese model based on VGG Face\n",
    "model = SiameseNetwork(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T15:26:24.981898Z",
     "iopub.status.busy": "2022-08-15T15:26:24.981635Z",
     "iopub.status.idle": "2022-08-15T15:55:15.396869Z",
     "shell.execute_reply": "2022-08-15T15:55:15.396140Z",
     "shell.execute_reply.started": "2022-08-15T15:26:24.981868Z"
    }
   },
   "outputs": [],
   "source": [
    "# load our data in an online manner\n",
    "data_generator = DataGenerator(dataset_path='../input/big-dataset/big_dataset/Train/', batch_size=20)\n",
    "\n",
    "# Train the model\n",
    "losses = []\n",
    "accuracy = []\n",
    "epochs = 30\n",
    "no_of_batches = len(data_generator)\n",
    "for i in range(1, epochs+1, 1):\n",
    "    loss = 0\n",
    "    with tqdm(total=no_of_batches) as pbar:\n",
    "        \n",
    "        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n",
    "        pbar.set_description_str(description)\n",
    "        \n",
    "        for j in range(no_of_batches):\n",
    "            data = data_generator[j]\n",
    "            temp = train(data)\n",
    "            loss += temp\n",
    "            \n",
    "            pbar.update()\n",
    "            print_statement = \"Loss :\" + str(temp.numpy())\n",
    "            pbar.set_postfix_str(print_statement)\n",
    "        \n",
    "        loss /= no_of_batches\n",
    "        \n",
    "        losses.append(loss.numpy())\n",
    "        print_statement = \"Loss :\" + str(loss.numpy())\n",
    "        pbar.set_postfix_str(print_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance computing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-08-15T16:04:45.666728Z",
     "iopub.status.busy": "2022-08-15T16:04:45.665955Z",
     "iopub.status.idle": "2022-08-15T16:04:55.946397Z",
     "shell.execute_reply": "2022-08-15T16:04:55.944521Z",
     "shell.execute_reply.started": "2022-08-15T16:04:45.666692Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create the training embeddings and labels \n",
    "data_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/train/')\n",
    "train_dict = data_generator.curate_dataset('../input/dataset6/dataset4/train/')\n",
    "labels = []\n",
    "features = []\n",
    "\n",
    "# compute the embeddings of the images\n",
    "i = 0\n",
    "for k, v in train_dict.items():\n",
    "    images = []\n",
    "    for e in v:\n",
    "        image_path = '../input/dataset6/dataset4/train/' + str(k) + '/' + str(e)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = np.asarray(image, dtype=np.float64)\n",
    "        images.append(image)\n",
    "\n",
    "    images = np.asarray(images)\n",
    "    images = preprocess_input(images)\n",
    "    images = tf.convert_to_tensor(images)\n",
    "    feature = model.get_features(images)\n",
    "    feature = tf.reduce_mean(feature, axis=0)\n",
    "    features.append(feature.numpy())\n",
    "    labels.append(k)\n",
    "    \n",
    "features = np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T15:33:59.543935Z",
     "iopub.status.busy": "2022-03-17T15:33:59.543679Z",
     "iopub.status.idle": "2022-03-17T15:34:01.05118Z",
     "shell.execute_reply": "2022-03-17T15:34:01.050396Z",
     "shell.execute_reply.started": "2022-03-17T15:33:59.543901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the training images and labels \n",
    "data_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/test/')\n",
    "test_dict = data_generator.curate_dataset('../input/dataset6/dataset4/test/')\n",
    "\n",
    "# prepare testing data\n",
    "labels_test = []\n",
    "images_test = []\n",
    "i = 0\n",
    "for k, v in test_dict.items():\n",
    "    for e in v:\n",
    "        image_path = '../input/dataset6/dataset4/test/' + str(k) + '/' + str(e)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = np.asarray(image, dtype=np.float64)\n",
    "        images_test.append(image)\n",
    "        labels_test.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T15:34:01.053595Z",
     "iopub.status.busy": "2022-03-17T15:34:01.053333Z",
     "iopub.status.idle": "2022-03-17T15:34:01.058815Z",
     "shell.execute_reply": "2022-03-17T15:34:01.058157Z",
     "shell.execute_reply.started": "2022-03-17T15:34:01.053561Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# shuffle the data\n",
    "features, labels = shuffle(features, labels)\n",
    "images_test, labels_test = shuffle(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T15:34:01.060436Z",
     "iopub.status.busy": "2022-03-17T15:34:01.059847Z",
     "iopub.status.idle": "2022-03-17T15:34:01.069788Z",
     "shell.execute_reply": "2022-03-17T15:34:01.06895Z",
     "shell.execute_reply.started": "2022-03-17T15:34:01.060399Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(images):\n",
    "    \"\"\"\n",
    "    This function compute the predictions.\n",
    "    \n",
    "    param: images: array of images that we want to predict their labels.\n",
    "    :return: list of predictions.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    for image in images:\n",
    "        image = preprocess_input(image)\n",
    "        img_features = model.get_features(np.expand_dims(image, axis=0))\n",
    "        dist = tf.norm(img_features - features, axis=1)\n",
    "        preds.append(labels[tf.argmin(dist)])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T15:34:01.07327Z",
     "iopub.status.busy": "2022-03-17T15:34:01.073024Z",
     "iopub.status.idle": "2022-03-17T15:34:20.625511Z",
     "shell.execute_reply": "2022-03-17T15:34:20.624874Z",
     "shell.execute_reply.started": "2022-03-17T15:34:01.073228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = predict(images_test)\n",
    "accuracy_score(preds, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T09:38:40.835969Z",
     "iopub.status.busy": "2022-03-15T09:38:40.835664Z",
     "iopub.status.idle": "2022-03-15T09:38:41.112947Z",
     "shell.execute_reply": "2022-03-15T09:38:41.112244Z",
     "shell.execute_reply.started": "2022-03-15T09:38:40.835926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of predicting an image\n",
    "import matplotlib.image as mpimg\n",
    "image_path = '../input/dataset5/dataset3/test/Adílio/Adílio17.jpeg'\n",
    "plt.imshow(mpimg.imread(image_path))\n",
    "image = cv2.imread(image_path)\n",
    "image = np.asarray(image, dtype=np.float64)\n",
    "predict([image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T16:05:01.535065Z",
     "iopub.status.busy": "2022-08-15T16:05:01.534591Z",
     "iopub.status.idle": "2022-08-15T16:14:05.191185Z",
     "shell.execute_reply": "2022-08-15T16:14:05.190253Z",
     "shell.execute_reply.started": "2022-08-15T16:05:01.535028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create labels and embedding for training\n",
    "train_dict = data_generator.curate_dataset('../input/big-dataset/big_dataset/Train/')\n",
    "labels_train = []\n",
    "features_train = []\n",
    "names_train = []\n",
    "\n",
    "# compute the embeddings \n",
    "for k, v in train_dict.items():\n",
    "    images = []\n",
    "    for e in v:\n",
    "        image_path = '../input/big-dataset/big_dataset/Train/' + str(k) + '/' + str(e)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = np.asarray(image, dtype=np.float64)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = preprocess_input(image)\n",
    "        img_features = model.get_features(np.expand_dims(image, axis=0))\n",
    "        features_train.append(img_features[0].numpy())\n",
    "        labels_train.append(k)\n",
    "        names_train.append(e)\n",
    "\n",
    "names_train = np.asarray(names_train)\n",
    "labels_train = np.asarray(labels_train)\n",
    "features_train = np.asarray(features_train)\n",
    "\n",
    "# save names, labels and embeddings in a .npy format\n",
    "np.save('names_train', names_train)\n",
    "np.save('labels_train', labels_train)\n",
    "np.save('features_train', features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T16:14:05.193932Z",
     "iopub.status.busy": "2022-08-15T16:14:05.193519Z",
     "iopub.status.idle": "2022-08-15T16:17:51.006976Z",
     "shell.execute_reply": "2022-08-15T16:17:51.005991Z",
     "shell.execute_reply.started": "2022-08-15T16:14:05.193897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create labels and embeddings for testing\n",
    "test_dict = data_generator.curate_dataset('../input/big-dataset/big_dataset/Test/')\n",
    "labels_test = []\n",
    "features_test = []\n",
    "names_test = []\n",
    "\n",
    "# compute embeddings\n",
    "for k, v in test_dict.items():\n",
    "    images = []\n",
    "    for e in v:\n",
    "        image_path = '../input/big-dataset/big_dataset/Test/' + str(k) + '/' + str(e)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = np.asarray(image, dtype=np.float64)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = preprocess_input(image)\n",
    "        img_features = model.get_features(np.expand_dims(image, axis=0))\n",
    "        features_test.append(img_features[0].numpy())\n",
    "        labels_test.append(k)\n",
    "        names_test.append(e)\n",
    "\n",
    "names_test = np.asarray(names_test)\n",
    "labels_test = np.asarray(labels_test)\n",
    "features_test = np.asarray(features_test)\n",
    "\n",
    "# save names, labels and embeddings in a .npy format\n",
    "np.save('names_test', names_test)\n",
    "np.save('labels_test', labels_test)\n",
    "np.save('features_test', features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:26:10.463404Z",
     "iopub.status.busy": "2022-08-15T19:26:10.462830Z",
     "iopub.status.idle": "2022-08-15T19:26:10.774393Z",
     "shell.execute_reply": "2022-08-15T19:26:10.773392Z",
     "shell.execute_reply.started": "2022-08-15T19:26:10.463365Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the npy files\n",
    "names_train = np.load('../input/embed-labels-names/names_train.npy')\n",
    "labels_train = np.load('../input/embed-labels-names/labels_train.npy')\n",
    "features_train = np.load('../input/embed-labels-names/features_train.npy')\n",
    "\n",
    "names_test = np.load('../input/embed-labels-names/names_test.npy')\n",
    "labels_test = np.load('../input/embed-labels-names/labels_test.npy')\n",
    "features_test = np.load('../input/embed-labels-names/features_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:26:11.813528Z",
     "iopub.status.busy": "2022-08-15T19:26:11.813256Z",
     "iopub.status.idle": "2022-08-15T19:26:11.876842Z",
     "shell.execute_reply": "2022-08-15T19:26:11.876122Z",
     "shell.execute_reply.started": "2022-08-15T19:26:11.813497Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# create dictionaries for embedding and names in order to pass them as argument to the cleaning function (get_clean_data)\n",
    "embeds_train_dict = defaultdict(list)\n",
    "names_train_dict = defaultdict(list)\n",
    "for i, k in enumerate(labels_train):\n",
    "    embeds_train_dict[k].append(features_train[i])\n",
    "    names_train_dict[k].append(names_train[i])\n",
    "\n",
    "names_test_dict = defaultdict(list)\n",
    "embeds_test_dict = defaultdict(list)\n",
    "for i, k in enumerate(labels_test):\n",
    "    embeds_test_dict[k].append(features_test[i])\n",
    "    names_test_dict[k].append(names_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:26:13.617430Z",
     "iopub.status.busy": "2022-08-15T19:26:13.616948Z",
     "iopub.status.idle": "2022-08-15T19:26:14.189621Z",
     "shell.execute_reply": "2022-08-15T19:26:14.188795Z",
     "shell.execute_reply.started": "2022-08-15T19:26:13.617393Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean the data\n",
    "outliers_train, clean_embed_train, clean_labels_train = get_clean_data(labels_train, embeds_train_dict, names_train_dict)\n",
    "outliers_test, clean_embed_test, clean_labels_test = get_clean_data(labels_test, embeds_test_dict, names_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:26:15.035099Z",
     "iopub.status.busy": "2022-08-15T19:26:15.034552Z",
     "iopub.status.idle": "2022-08-15T19:26:15.055927Z",
     "shell.execute_reply": "2022-08-15T19:26:15.054984Z",
     "shell.execute_reply.started": "2022-08-15T19:26:15.035055Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# shuffle the data\n",
    "clean_embed_train, clean_labels_train = shuffle(clean_embed_train, clean_labels_train)\n",
    "clean_embed_test, clean_labels_test = shuffle(clean_embed_test, clean_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T16:45:53.940901Z",
     "iopub.status.busy": "2022-08-15T16:45:53.940124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use SVM classifier with GridSearchCV to classfy these embedding\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters)\n",
    "clf.fit(clean_embed_train, clean_labels_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Accuracy\n",
    "preds = clf.predict(clean_embed_test)\n",
    "print(\"Accuracy :  \", accuracy_score(clean_labels_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:29:05.687597Z",
     "iopub.status.busy": "2022-08-15T19:29:05.686744Z",
     "iopub.status.idle": "2022-08-15T19:29:05.695991Z",
     "shell.execute_reply": "2022-08-15T19:29:05.695258Z",
     "shell.execute_reply.started": "2022-08-15T19:29:05.687554Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:31:09.333795Z",
     "iopub.status.busy": "2022-08-15T19:31:09.333470Z",
     "iopub.status.idle": "2022-08-15T19:31:09.343897Z",
     "shell.execute_reply": "2022-08-15T19:31:09.342987Z",
     "shell.execute_reply.started": "2022-08-15T19:31:09.333743Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(list(clean_labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:31:37.215002Z",
     "iopub.status.busy": "2022-08-15T19:31:37.214329Z",
     "iopub.status.idle": "2022-08-15T19:31:37.275454Z",
     "shell.execute_reply": "2022-08-15T19:31:37.274611Z",
     "shell.execute_reply.started": "2022-08-15T19:31:37.214963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transfort the labels to integers\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(clean_labels_test) + list(clean_labels_train))\n",
    "encoded_labels_train = le.transform(clean_labels_train)\n",
    "encoded_labels_test = le.transform(clean_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T19:31:42.104499Z",
     "iopub.status.busy": "2022-08-15T19:31:42.103943Z",
     "iopub.status.idle": "2022-08-15T20:01:30.298808Z",
     "shell.execute_reply": "2022-08-15T20:01:30.295187Z",
     "shell.execute_reply.started": "2022-08-15T19:31:42.104458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier and find the best parameters using Random Search Cross Validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "clf_random.fit(clean_embed_train, encoded_labels_train)\n",
    "print(clf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-15T20:01:30.300364Z",
     "iopub.status.idle": "2022-08-15T20:01:30.300923Z",
     "shell.execute_reply": "2022-08-15T20:01:30.300702Z",
     "shell.execute_reply.started": "2022-08-15T20:01:30.300675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = clf_random.predict(clean_embed_test)\n",
    "print(\"Accuracy :  \", accuracy_score(encoded_labels_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
